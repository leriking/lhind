{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "from io import StringIO\n",
    "\n",
    "# Azure connection details\n",
    "connection_string = \"DefaultEndpointsProtocol=https;AccountName=lhindstorage;AccountKey=SPFV+Hdv7AWTGTpysBBwEVXJvefoYSSr17wLSWB+onc3PMYbwXEcpFRZvHvXF06eePtCy00PIvZu+AStpz1VzA==;EndpointSuffix=core.windows.net\"\n",
    "container_name = \"clean-data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File names in the container\n",
    "files = {\n",
    "    \"order_items\": \"order_items.csv\",\n",
    "    \"orders\": \"orders.csv\",\n",
    "    \"order_payments\": \"order_payments.csv\",\n",
    "    \"products\": \"products.csv\"\n",
    "}\n",
    "\n",
    "# Initialize BlobServiceClient\n",
    "blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
    "container_client = blob_service_client.get_container_client(container_name)\n",
    "\n",
    "# Function to load a CSV file from Azure Blob Storage into a DataFrame\n",
    "def load_csv_from_blob(blob_name):\n",
    "    blob_client = container_client.get_blob_client(blob_name)\n",
    "    download_stream = blob_client.download_blob()\n",
    "    content = download_stream.readall().decode(\"utf-8\")\n",
    "    return pd.read_csv(StringIO(content))\n",
    "\n",
    "# Load datasets\n",
    "order_items = load_csv_from_blob(files[\"order_items\"])\n",
    "orders = load_csv_from_blob(files[\"orders\"])\n",
    "order_payments = load_csv_from_blob(files[\"order_payments\"])\n",
    "products = load_csv_from_blob(files[\"products\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure datetime conversion on orders table\n",
    "orders['order_purchase_timestamp'] = pd.to_datetime(orders['order_purchase_timestamp'])\n",
    "orders['order_delivered_customer_date'] = pd.to_datetime(orders['order_delivered_customer_date'])\n",
    "\n",
    "# Rename selected columns for clean merge\n",
    "orders_subset = orders[['order_id', 'customer_id', 'order_purchase_timestamp', 'order_delivered_customer_date']].copy()\n",
    "orders_subset.rename(columns={\n",
    "    'customer_id': 'order_customer_id',\n",
    "    'order_purchase_timestamp': 'order_purchase_ts',\n",
    "    'order_delivered_customer_date': 'order_delivered_ts'\n",
    "}, inplace=True)\n",
    "\n",
    "# Merge into order_items\n",
    "order_items = order_items.merge(orders_subset, on='order_id', how='left')\n",
    "\n",
    "# Create total_price\n",
    "if 'total_price' not in order_items.columns:\n",
    "    order_items['total_price'] = order_items['price'].astype(float) + order_items['freight_value'].astype(float)\n",
    "\n",
    "# Drop rows with missing critical values\n",
    "order_items.dropna(subset=['order_customer_id', 'order_purchase_ts', 'delivery_time_days'], inplace=True)\n",
    "\n",
    "# Cumulative sales per customer\n",
    "order_items = order_items.sort_values(by=['order_customer_id', 'order_purchase_ts'])\n",
    "order_items['cumulative_sales_per_customer'] = (\n",
    "    order_items.groupby('order_customer_id')['total_price'].cumsum()\n",
    ")\n",
    "\n",
    "#  Merge product category\n",
    "order_items = order_items.merge(\n",
    "    products[['product_id', 'product_category_name']],\n",
    "    on='product_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "#  Drop missing categories\n",
    "order_items.dropna(subset=['product_category_name'], inplace=True)\n",
    "\n",
    "# Rolling average delivery time per category (window=5)\n",
    "order_items = order_items.sort_values(by=['product_category_name', 'order_purchase_ts'])\n",
    "order_items['avg_delivery_time_per_category'] = (\n",
    "    order_items\n",
    "    .groupby('product_category_name')['delivery_time_days']\n",
    "    .apply(lambda x: x.reset_index(drop=True).rolling(window=5, min_periods=1).mean())\n",
    "    .reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_df_to_blob(df, blob_name):\n",
    "    \n",
    "    # Write to StringIO (text stream)\n",
    "    csv_buffer = StringIO()\n",
    "    df.to_csv(csv_buffer, index=False)\n",
    "\n",
    "    # Convert to bytes before uploading\n",
    "    csv_bytes = csv_buffer.getvalue().encode(\"utf-8\")\n",
    "    container_client.upload_blob(name=blob_name, data=csv_bytes, overwrite=True)\n",
    "\n",
    "# Save results\n",
    "save_df_to_blob(order_items, \"rolling_avg_cumulative_sales.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
